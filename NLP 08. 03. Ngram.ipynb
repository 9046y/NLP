{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The BigramTagger subclass uses the previous tag as part of its context, while the TrigramTagger subclass uses the \n",
    "previous two tags. An ngram is a subsequence of n items.\n",
    "\n",
    "By themselves, BigramTagger and TrigramTagger perform quite poorly. This is partly because they cannot learn context \n",
    "from the  rst word(s) in a sentence. Since a UnigramTagger class doesn't care about the previous context, it is able \n",
    "to have higher baseline accuracy by simply guessing the most common tag for each word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11318799913662854"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import treebank\n",
    "test_sents = treebank.tagged_sents()[3000:]\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "\n",
    "from nltk.tag import BigramTagger, TrigramTagger\n",
    "bitagger = BigramTagger(train_sents)\n",
    "bitagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06889704295273041"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tritagger = TrigramTagger(train_sents)\n",
    "tritagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Backoff tagging is one of the core features of SequentialBackoffTagger. It allows you to chain taggers together so\n",
    "that if one tagger doesn't know how to tag a word, it can pass the word on to the next backoff tagger. If that one\n",
    "can't do it, it can pass the word on to the next backoff tagger, and so on until there are no backoff taggers left\n",
    "to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88076840060436"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "     for cls in tagger_classes:\n",
    "       backoff = cls(train_sents, backoff=backoff)\n",
    "     return backoff\n",
    "\n",
    "from nltk.tag import DefaultTagger,BigramTagger, TrigramTagger, UnigramTagger\n",
    "\n",
    "backoff = DefaultTagger('NN')\n",
    "tagger = backoff_tagger(train_sents, [UnigramTagger, BigramTagger, TrigramTagger], backoff=backoff)\n",
    "tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
