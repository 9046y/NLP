{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A corpus is a collection of text documents, and corpora is the plural of corpus. This comes from the Latin word for \n",
    "body; in this case, a body of text. So a custom corpus is really just a bunch of text  les in a directory, \n",
    "often alongside many other directories of text  les.\n",
    "\n",
    "\n",
    "The TreebankWordTokenizer class uses conventions found in the Penn Treebank corpus. This corpus is one of the\n",
    "most used corpora for natural language processing, and was created in the 1980s by annotating articles from \n",
    "the Wall Street Journal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "words.fileids()\n",
    "len(words.words('en-basic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words.words('en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLTK also comes with a large list of English words. There's one with 850 basic words, and another list with over \n",
    "200,000 known English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the Gutenberg Bible, and reading the first few lines:\n",
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# sample text\n",
    "sample = gutenberg.raw(\"bible-kjv.txt\")\n",
    "\n",
    "tok = sent_tokenize(sample)\n",
    "\n",
    "for x in range(5):\n",
    "    print(tok[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure\n",
      "belles_lettres\n",
      "editorial\n",
      "fiction\n",
      "government\n",
      "hobbies\n",
      "humor\n",
      "learned\n",
      "lore\n",
      "mystery\n",
      "news\n",
      "religion\n",
      "reviews\n",
      "romance\n",
      "science_fiction\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "for name in brown.categories():\n",
    "    print( name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
